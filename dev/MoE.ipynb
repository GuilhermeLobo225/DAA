{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf913fd5",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c326314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.feature_selection import chi2\n",
    "from sko.PSO import PSO\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from scipy.stats import ttest_rel\n",
    "from statistics import mean, stdev\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import defaultdict\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b91d2",
   "metadata": {},
   "source": [
    "### **Data Ingestion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento de Dados\n",
    "test = pd.read_csv(r'../datasets/test_data_cleaned.csv')\n",
    "train = pd.read_csv(r'../datasets/training_data_cleaned.csv')\n",
    "train = train.drop(columns=['hour'])\n",
    "test = test.drop(columns=['hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8a993",
   "metadata": {},
   "source": [
    "### **Data Segregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f2d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['AVERAGE_SPEED_DIFF']\n",
    "X = train.drop(columns=['AVERAGE_SPEED_DIFF'])\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04854421",
   "metadata": {},
   "source": [
    "### **Model Training** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb8525c",
   "metadata": {},
   "source": [
    "#### *Specialists Models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0,1,2,3,4]\n",
    "inverse_map = {0:'None', 1:'Low', 2:'Medium', 3:'High', 4:'Very_High'}\n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2025)\n",
    "\n",
    "# Store specialists per fold\n",
    "specialists = {cls: [] for cls in classes}\n",
    "\n",
    "# Store results per fold\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Train each specialist in a One vs Rest way\n",
    "    fold_preds = np.zeros((len(X_val_fold), len(classes)))\n",
    "    \n",
    "    for cls in classes:\n",
    "        # Apply SMOTE\n",
    "        sm = SMOTE(random_state=2025)\n",
    "        # Alternatives\n",
    "        #sm = SMOTEENN(random_state=2025)\n",
    "        #sm = ADASYN(random_state=2025)\n",
    "\n",
    "        # Split \n",
    "        X_train_res, y_train_res = sm.fit_resample(X_train_fold, (y_train_fold == cls).astype(int))\n",
    "\n",
    "        # Define model\n",
    "        model = RandomForestClassifier(n_estimators=118,max_depth=27,min_samples_split=2,min_samples_leaf=1,criterion='gini',class_weight=\"balanced\",random_state=2025,n_jobs=-1)\n",
    "        \n",
    "        # Train and store model\n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        specialists[cls].append(model)\n",
    "        \n",
    "        # Probability of a specialist in a validation fold\n",
    "        fold_preds[:, cls] = model.predict_proba(X_val_fold)[:,1]\n",
    "    \n",
    "    # Final prediction (argmax of said probabilities)\n",
    "    y_val_pred = np.argmax(fold_preds, axis=1)\n",
    "    \n",
    "    # Save metrics\n",
    "    fold_results.append({\"fold\": fold,\"accuracy\": accuracy_score(y_val_fold, y_val_pred),\"report\": classification_report(y_val_fold, y_val_pred, output_dict=True)})\n",
    "    \n",
    "    # Show Folds\n",
    "    print(classification_report(y_val_fold, y_val_pred))\n",
    "\n",
    "# Accuracy and deviation\n",
    "acc_list = [f['accuracy'] for f in fold_results]\n",
    "print(\"\\n=== Resumo Geral ===\")\n",
    "print(f\"Accuracy média: {np.mean(acc_list):.4f}\")\n",
    "print(f\"Desvio padrão: {np.std(acc_list):.4f}\")\n",
    "\n",
    "# F1-score per classe\n",
    "metrics_per_class = defaultdict(list)\n",
    "\n",
    "for f in fold_results:\n",
    "    for cls in map(str, classes):\n",
    "        metrics_per_class[cls].append(f['report'][cls]['f1-score'])\n",
    "\n",
    "print(\"\\nF1-score médio por classe:\")\n",
    "for cls in classes:\n",
    "    print(f\"{inverse_map[cls]}: {np.mean(metrics_per_class[str(cls)]):.4f} ± {np.std(metrics_per_class[str(cls)]):.4f}\")\n",
    "\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_specialists(X_input, specialists, classes):\n",
    "    probs = []\n",
    "    for cls in classes:\n",
    "        prob_cls = np.mean([m.predict_proba(X_input)[:,1] for m in specialists[cls]], axis=0)\n",
    "        probs.append(prob_cls)\n",
    "    probs = np.vstack(probs).T\n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "    return y_pred, probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e0dff",
   "metadata": {},
   "source": [
    "### **Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialistsEnsemble(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, specialists, classes):\n",
    "        self.specialists = specialists\n",
    "        self.classes = classes\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probs = []\n",
    "        for cls in self.classes:\n",
    "            cls_probs = np.mean(\n",
    "                [m.predict_proba(X)[:, 1] for m in self.specialists[cls]],\n",
    "                axis=0\n",
    "            )\n",
    "            probs.append(cls_probs)\n",
    "\n",
    "        probs = np.vstack(probs).T\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "ensemble_model = SpecialistsEnsemble(\n",
    "    specialists=specialists,\n",
    "    classes=classes\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = permutation_importance(ensemble_model,X_val_fold,y_val_fold,n_repeats=10,random_state=42,n_jobs=2)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "p_importances = pd.Series(\n",
    "    result.importances_mean,\n",
    "    index=X_val_fold.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"Feature importances using Permutation Importance:\\n\", p_importances)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "p_importances.plot.barh(\n",
    "    yerr=result.importances_std,\n",
    "    ax=ax,\n",
    "    color=\"grey\"\n",
    ")\n",
    "ax.grid(axis=\"y\")\n",
    "ax.set_xlabel(\"Mean decrease in accuracy\", fontsize=18)\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.tick_params(axis=\"x\", labelsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f5549",
   "metadata": {},
   "source": [
    "### **Submission Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a04586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(input_csv_path,output_csv_path,specialists,classes,inverse_map,start_rowid=1):\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    X_input = df.copy()\n",
    "    # Predictions\n",
    "    y_pred, _ = predict_specialists(X_input, specialists, classes)\n",
    "\n",
    "    # RowId based on line (to meet format)\n",
    "    row_ids = np.arange(start_rowid, start_rowid + len(df))\n",
    "\n",
    "    # Create submission\n",
    "    submission = pd.DataFrame({\n",
    "        \"RowId\": row_ids,\n",
    "        \"Speed_Diff\": [inverse_map[c] for c in y_pred]\n",
    "    })\n",
    "\n",
    "    # Export\n",
    "    submission.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Submission criada: {output_csv_path}\")\n",
    "\n",
    "generate_submission(input_csv_path=r\"../datasets/test_data_cleaned.csv\",output_csv_path=r\"../submission.csv\",specialists=specialists,classes=classes,inverse_map=inverse_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1a64d",
   "metadata": {},
   "source": [
    "### **Mixture of Experts (MoE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8912fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(y.unique())\n",
    "inverse_map = {0: \"None\",1: \"Low\",2: \"Medium\",3: \"High\",4: \"Very_High\"}\n",
    "\n",
    "# Stratified\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,stratify=y,random_state=2025)\n",
    "\n",
    "# Train loop of the MoE\n",
    "def train_moe(X, y,n_experts=3,n_splits=5,random_state=2025):\n",
    "    # Stratified k Fold\n",
    "    skf = StratifiedKFold(n_splits=n_splits,shuffle=True,random_state=random_state)\n",
    "\n",
    "    experts = [[] for _ in range(n_experts)]\n",
    "    gates = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # Oversampling (MULTICLASS)\n",
    "        smote = SMOTE(random_state=random_state)\n",
    "        X_res, y_res = smote.fit_resample(X_tr, y_tr)\n",
    "\n",
    "        # Train experts\n",
    "        for i in range(n_experts):\n",
    "            expert = RandomForestClassifier(n_estimators=118,max_depth=27,min_samples_split=2,min_samples_leaf=1,criterion='gini',class_weight=\"balanced\",random_state=random_state + i,n_jobs=-1)\n",
    "            expert.fit(X_res, y_res)\n",
    "            experts[i].append(expert)\n",
    "\n",
    "        # Train gate\n",
    "        gate = RandomForestClassifier(n_estimators=118,max_depth=27,min_samples_split=2,min_samples_leaf=1,criterion='gini',class_weight=\"balanced\",random_state=random_state + i,n_jobs=-1)\n",
    "        gate.fit(X_tr, y_tr)\n",
    "        gates.append(gate)\n",
    "\n",
    "    return experts, gates\n",
    "\n",
    "# Predict with MoE\n",
    "def predict_moe(X, experts, gates):\n",
    "    n_experts = len(experts)\n",
    "    n_samples = len(X)\n",
    "    n_classes = experts[0][0].n_classes_\n",
    "\n",
    "    # Expert probabilities\n",
    "    expert_probs = np.zeros((n_experts, n_samples, n_classes))\n",
    "\n",
    "    for i, expert_list in enumerate(experts):\n",
    "        fold_probs = [m.predict_proba(X) for m in expert_list]\n",
    "        expert_probs[i] = np.mean(fold_probs, axis=0)\n",
    "\n",
    "    # Gate weights\n",
    "    gate_weights = np.mean([g.predict_proba(X) for g in gates],axis=0)  # shape: (n_samples, n_classes)\n",
    "\n",
    "    # Normalize to expert count\n",
    "    gate_weights = gate_weights[:, :n_experts]\n",
    "    gate_weights = gate_weights / gate_weights.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Mixture\n",
    "    final_probs = np.zeros((n_samples, n_classes))\n",
    "    for i in range(n_experts):\n",
    "        final_probs += gate_weights[:, i, None] * expert_probs[i]\n",
    "\n",
    "    y_pred = np.argmax(final_probs, axis=1)\n",
    "    return y_pred, final_probs\n",
    "\n",
    "\n",
    "# Call training\n",
    "experts, gates = train_moe(X_train,y_train,n_experts=5,n_splits=5)\n",
    "\n",
    "# Call predict\n",
    "y_test_pred, y_test_probs = predict_moe(X_test, experts, gates)\n",
    "\n",
    "# Metrics\n",
    "print(\"\\n=== FINAL MODEL PERFORMANCE ===\\n\")\n",
    "print(classification_report(y_test,y_test_pred,target_names=[inverse_map[c] for c in classes],digits=4))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[inverse_map[c] for c in classes])\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix – Mixture of Experts\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84d0128",
   "metadata": {},
   "source": [
    "### **Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoEEnsemble(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, experts, gates):\n",
    "        self.experts = experts\n",
    "        self.gates = gates\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        n_experts = len(self.experts)\n",
    "        n_samples = len(X)\n",
    "        n_classes = self.experts[0][0].n_classes_\n",
    "\n",
    "        # Expert probabilities\n",
    "        expert_probs = np.zeros((n_experts, n_samples, n_classes))\n",
    "        for i, expert_list in enumerate(self.experts):\n",
    "            fold_probs = [m.predict_proba(X) for m in expert_list]\n",
    "            expert_probs[i] = np.mean(fold_probs, axis=0)\n",
    "\n",
    "        # Gate weights\n",
    "        gate_weights = np.mean(\n",
    "            [g.predict_proba(X) for g in self.gates],\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        # Normalize to number of experts\n",
    "        gate_weights = gate_weights[:, :n_experts]\n",
    "        gate_weights = gate_weights / gate_weights.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # Mixture\n",
    "        final_probs = np.zeros((n_samples, n_classes))\n",
    "        for i in range(n_experts):\n",
    "            final_probs += gate_weights[:, i, None] * expert_probs[i]\n",
    "\n",
    "        return final_probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "    \n",
    "moe_model = MoEEnsemble(experts=experts,gates=gates)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = permutation_importance(moe_model,X_test,y_test,n_repeats=10,random_state=42,n_jobs=2)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "\n",
    "p_importances = (\n",
    "    pd.Series(result.importances_mean, index=X_test.columns)\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Feature importances using Permutation Importance:\\n\", p_importances)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "p_importances.plot.barh(yerr=result.importances_std,ax=ax,color=\"grey\")\n",
    "ax.grid(axis=\"y\")\n",
    "ax.set_xlabel(\"Mean decrease in accuracy\", fontsize=18)\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.tick_params(axis=\"x\", labelsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa23618",
   "metadata": {},
   "source": [
    "### **Submission Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(input_csv_path,output_csv_path,experts,gates,inverse_map,start_rowid=1):\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    X_input = df.copy()\n",
    "\n",
    "    # Predict with MoE\n",
    "    y_pred, _ = predict_moe(X_input, experts, gates)\n",
    "\n",
    "    # RowId based on line number\n",
    "    row_ids = np.arange(start_rowid, start_rowid + len(df))\n",
    "\n",
    "    # Create submission\n",
    "    submission = pd.DataFrame({\n",
    "        \"RowId\": row_ids,\n",
    "        \"Speed_Diff\": [inverse_map[int(c)] for c in y_pred]\n",
    "    })\n",
    "\n",
    "    # Export\n",
    "    submission.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Submission criada: {output_csv_path}\")\n",
    "\n",
    "generate_submission(input_csv_path=r\"../datasets/test_data_cleaned.csv\",output_csv_path=r\"../submission.csv\",experts=experts,gates=gates,inverse_map=inverse_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
